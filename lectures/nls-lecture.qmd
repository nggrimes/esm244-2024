---
title: "Non-linear Least Squares"
subtitle: "ESM 244 2024"
author: "Nathaniel Grimes"
institute: "Bren School of Environmental Science"
date: last-modified
format: 
  revealjs:
    chalkboard: true
    slide-number: true
    show-slide-number: print
    theme: [default, ucsb.scss]
    logo: img/bren-logo.png
editor: visual
---

## Quick Aside

I made this presentation in Quarto using RevealJS. The code is up on Canvas if you want to see more ways Quarto can be used beyond just homework assignments

::: columns
::: {.column width="55%"}
**Pros**

-   Easily integrate R code

-   Update figures automatically

-   Living presentation with html features

-   Easier to write math through Latex and MathJax
:::

::: {.column width="40%"}
**Cons**

-   Define everything in code, no easy powerpoint tools

-   Maybe not as "sexy" as other presentations
:::
:::

## Packages to follow along with

```{r}
#| echo: true

library(tidyverse)
#remotes::install_github("lter/lterdatasampler")
library(lterdatasampler)
library(knitr)
library(broom)
library(investr)
library(kableExtra)
```

```{r}
#| echo: false
library(gstat)
```

## What is Non-linear Least Squares? {background-color="#003660"}

## Remember what Ordinary Least Squares does first



The Fundamental Objective of OLS

::: columns
::: {.column width="45%"}
```{r, fig.dim=c(6,6)}
fit<-lm(mpg~hp,data=mtcars)

d<-mtcars
d$predicted<-predict(fit)
d$residuals<-residuals(fit)

ggplot(d,aes(x=hp,y=mpg))+
  geom_point(size=4)+
  theme_bw()+
  theme(axis.title = element_text(size=28),axis.text = element_text(size=20))
  
```
:::

::: {.column width="55%"}
::: fragment
-   Best Fit a Line to Data
:::

::: fragment
-   How Does OLS Fit a Line to Data?

Hint:

$\hat{\beta}=\frac{\sum^n_{i=1}(x_i-\bar{x})(y_i-\bar{y})}{\sum^n_{i=1}(x_i-\bar{x})^2}$
:::
:::
:::

## Remember what Ordinary Least Squares does first

<br/>

::: columns
::: {.column width="45%"}
```{r,fig.dim=c(6,6)}

#| fig-align='center'
#| fig-width=6
#| fig-height=10
ggplot(d,aes(x=hp,y=mpg))+
  geom_smooth(method = "lm",se=FALSE,color="blue")+geom_segment(aes(xend=hp,yend=predicted),alpha=.2)+
  geom_point(size=4)+
  geom_point(aes(y=predicted),size=4,shape=1)+
  theme_bw()+
  theme(axis.title = element_text(size=28),axis.text = element_text(size=20))
```
:::

::: {.column width="55%"}
How does OLS fit the line?

-   Minimize squared error (aka residuals)

$\hat\beta=\min_\beta \sum^n_{i=1}\hat{\epsilon_i}^2=\sum^n_{i=1}(y_i-\beta x_i)^2$
:::
:::

## OLS is simple and powerful

::: incremental
**What are some limitations of OLS?**

-   Linear relationship between predictor (y) and variables (x)

-   Multicollinearity

-   Errors normally distributed

-   Homoscedasticity

-   Sensitive to outliers
:::

## What if we get something like this?

```{r, fig.dim = c(12, 7),fig.align='center'}
knz_bison_age <- knz_bison %>% 
  mutate(animal_age = rec_year - animal_yob) %>% 
  filter(animal_sex=="F")
  

ggplot(data=knz_bison_age)+
  geom_point(aes(x=animal_age,y=animal_weight),size=2.5,alpha=0.2,color='purple')+
  theme_minimal()+
  xlab('Age')+
  ylab('Weight')+
  ggtitle("Female Bison from Konza Prairie")+
  theme(axis.title = element_text(size=26),axis.text = element_text(size=20))+
  theme(plot.title = element_text(size=28,hjust=0.5))
```

## Or this?

![](img/refractivity.PNG){fig-align="center"}

## In specific applications, accuracy greatly matters!

![](img/vtrpe_run.PNG){fig-align="center"}

## Nonlinear Least Squares

Apply the same idea of least squares error minimization, but with any function

$$
\begin{aligned}
y_i&=f(x_i,\boldsymbol\beta)+\epsilon_i &\text{(1)}\\
\min_{\boldsymbol\beta}&=\sum^n_{i=1}\epsilon_i^2=\sum^n_{i=1}(y_i-f(x_i,\boldsymbol\beta))^2 &\text{(2)}
\end{aligned}
$$

General idea is very similar, but implementation and use is quite different

::: notes
Notice the xB is replaced by a general function.
:::

## How NLS works

No simple analytical solution like in OLS (Solve for $\hat\beta$)

Iteratively approximate the solution through algorithms

-   Gauss-Newton (Most Common)

-   Levenberg-Marquardt (More flexible)

Approximate the function's gradient (think derivative), then move along until a convergence criteria is met

$$
|\frac{\overbrace{S^k}^{\text{Previous squared errror}}-\overbrace{S^{k+1}}^{\text{Updated squared error}}}{S^k}|<0.0001
$$

## You have already used these algorithms before

```{r}
#| fig-align: center
library(sf)
library(gstat)
pop_den_sf<-read_sf(here::here("data","lab_4","pop_dens","sbc_pop_dens.shp")) %>% janitor::clean_names()


pop_log<-pop_den_sf %>% 
  mutate(log_pop=log(popdens))

log_vgm <- gstat::variogram(log_pop ~ 1, data =pop_log )

log_fit_nug <- fit.variogram(log_vgm,
                         model = vgm(model = "Gau", nugget = TRUE))

plot(log_vgm,log_fit_nug)
```

fit.variogram uses a Levenberg-Marquardt to find the nugget, sill, and range

## Demonstration of Gauss-Newton Algorithm {#sec-algo}

::: columns
::: {.column width="50%"}
![](https://i.stack.imgur.com/gdJ3v.gif)
:::

::: {.column width="50%"}
-   Global minimum at a=2.25

-   Begins at initial guess of a=3.5

-   Step size depends on the 2nd order approximation

-   Keeps going until the [green]{.seagreen} line (first derivative) reaches close to zero
:::
:::

## Why should we use NLS?

We need far fewer assumptions than multiple regression

-   Residuals do not have to be normally distributed

-   No linear relationship required

-   Don't care about homoscedasticity

If underlying model is smooth, can find solutions accurately and quickly compared to other methods

## When to use NLS

Best suited for specific model parameterization given a collection of data

Have a known equation and want to fit parameters

[There is no $R^2$ value to compare across model specifications, but we can still test model performance using AIC or Cross Fold Validation through RMSE (In lab this week!)]{.small-text}

## Pitfalls (literally) and warnings

::: columns
::: {.column width="50%"}
NLS is only as good as the underlying model. [Bring your brain to the party]{.gold-bold} and make sure the model you're fitting is appropriate

Follows gradient of steepest descent $\rightarrow$ local min/max valleys

-   With n-parameters chances of local min/max rises
:::

::: {.column width="50%"}
```{r, out.width="85%",fig.align='center'}
knitr::include_graphics("img/minmax.png")
```

Requires good initial guesses

-   Comes from algorithms [Click back to slide](#sec-algo)
:::
:::

## Know when to use NLS or another option

```{r, out.width="55%",fig.align='center'}
knitr::include_graphics("img/vtrpe_run.PNG")
```

-   [In this research we ended up using Genetic Algorithms instead as they provide global solutions without having to guess]{.small-text}

-   [Operationally, the Navy doesn't have time to guess]{.small-text}

## Using NLS in R {background-color="#003660"}

## Implementation Framework

- Step 1: Identify $f(x,\beta)$
    
    - Use Literature or build your own from theoretical justification
    
- Step 2: Build $f(x,\beta)$ as an R function

- Step 3: Find initial guesses

- Step 4: Combine everything and run with `nls()`

- Step 5: Evaluate results

## Let's apply NLS to our Female Bisons

```{r bisonfollow,echo=TRUE}
knz_bison_age <- knz_bison %>% 
  mutate(animal_age = rec_year - animal_yob) %>% 
  filter(animal_sex=="F")
```

```{r bisongraph, out.width="35%",fig.align='center'}
knz_plt<-ggplot(data=knz_bison_age)+
  geom_point(aes(x=animal_age,y=animal_weight),size=1,alpha=0.2,color='purple')+
  theme_minimal()+
  xlab('Age')+
  ylab('Weight')+
  ggtitle("Female Bison from Konza Prairie")+
  theme(axis.title = element_text(size=28),axis.text = element_text(size=20))+
  theme(plot.title = element_text(size=28,hjust=0.5))

knz_plt
```


## Bison Restoration needs accurate ecosystem and population models{background-image="img/apf-bis.jpg"}

<br/>

::: box
Fit data from Konza Prairie LTER to inform Sun Prairie Restoration Efforts
:::

##
![](img/bis-car.jpg){fig-align="center"}

## 
![](img/bis-hike.jpg){fig-align="center"}

## Use R Built in functions

```{r nls, echo=TRUE,eval=FALSE}
df_nls<-nls(formula=   # Model we want to estimate,
            data   # Data we are evaluating,
            start  # Our initial guesses
            control # List of tolerance value, etc
            trace  # Do we want to see convergence
            upper  # Bounds on input parameters
            ... # some other useful stuff )
```

## Step 1: What Model to use?

Martin and Barboza (2020) used a Gompertz model to predict bison mass

$$BM=b1*exp(-exp(-b2*(age-b3)))$$

::: columns
::: {.column width="50%"}
[$b1$ = asymptotic body mass (pounds)]{.small-text}

[$b2$ = instantaneous growth-rate]{.small-text}

[$b3$ = age at inflection point years]{.small-text}

[$age$ = Independent variable]{.small-text}

[$BM$ = Body mass (pounds) Dependent variable]{.small-text}
:::

::: {.column width="50%"}
```{r gompertz,out.width="85%"}
gompertz<-function(b1,b2,b3,age){
 BM= b1*exp(-exp(-b2*(age-b3)))
return(BM)
}

b1=800
b2=1.25
b3=0.5

x=seq(from=0, to=20,length.out=100)

g1=gompertz(b1,b2,b3,x)

df1=data.frame(age=x,weight=g1)

df1plt<-ggplot(data=df1,aes(x=age,y=weight))+
  geom_line(color="darkorchid",size=2)+
  theme_minimal()+
  ylim(c(50,1000))+
  ggtitle("Example Gompertz")+
  theme(axis.title = element_text(size=28),axis.text = element_text(size=20))+
  theme(plot.title = element_text(size=30,hjust=0.5))

df1plt
```
:::
:::

## Step 2: Build R function

```{r model, echo=TRUE}
gompertz<-function(b1,b2,b3,age){
 BM= b1*exp(-exp(-b2*(age-b3)))
return(BM)
}
```

<br/>

<br/>

[Note: For the nls function it's okay to define all parameters like we did. In other optimization tools (e.g. optim) you would want to keep the first input index as a vector if you have multiple choice variables]{.small-text}

## Step 3: Provide Guesses

```{r nlsguess, echo=TRUE,eval=FALSE}
#| code-line-numbers: "3"
df_nls<-nls(animal_weight~gompertz(b1,b2,b3,animal_age),   
            data=knz_bison_age,   
            start=list(b1=?,b2=?,b3=?),
            trace=TRUE )
```

<br/>

The initial guesses and `data` variable also tell nls which variables we are trying to find from our data

## Step 3: Provide Guesses

*4 methods for providing guesses* 

1)  Use past parameters from similar studies

2)  Use data to internally define guesses (min, mean, max, etc.)

3)  In 2-D, look at the graphs and estimate

4)  In N-D, combine steps 1-2 then create a start grid to search over

## Interactive applied guesses {#sec-interactive}

<iframe src="https://nggrimes.shinyapps.io/bison_app/" height="1200" width="1000">
  
  </iframe>
  
  <br/>
  
  [Link to static slides](#sec-model){.small-text}

## Step 4: Run Model

```{r nlsrun,echo=TRUE,results=TRUE}
b_gompertz<-nls(animal_weight~gompertz(b1,b2,b3,animal_age),
                      data = knz_bison_age,
                      start = list(b1=1000,b2=1,b3=0.6),
                      trace = TRUE)
```

## Step 5: What did the model find?

```{css echo=FALSE}
.small-code{
font-size: 75%;
}
```

::: small-code
```{r nlssummary,echo=TRUE,results=TRUE}
tidy(b_gompertz) %>% 
  kable() %>% 
  kable_classic()

```

```{r nlsglance,echo=TRUE,results=TRUE}
glance(b_gompertz) %>% 
  kable() %>% 
  kable_classic()


```
:::

## How well does the model predict?

```{r predict,echo=FALSE}
age_series <- seq(0, 22, by = 0.1)

# Make predictions using the model over those times: 
pred <- predict(b_gompertz, list(animal_age = age_series))

# Bind the predictions and age sequence together into a data frame: 
bison_f_predicted <- data.frame(age_series, pred)
```

```{r, fig.align='center'}
# Plot the observed data and predictions together:
ggplot() +
  geom_point(data = knz_bison_age, 
             aes(x = animal_age, y = animal_weight),
             size = 1,
             alpha = 0.2,color="darkorchid") +
  geom_line(data = bison_f_predicted, 
            aes(x = age_series, y = pred),
            color = "blue",
            size = 1) +
  theme_minimal()+
    xlab('Age')+
  ylab('Weight')+
  ggtitle("NLS Model Prediction of bison females")+
  theme(axis.title = element_text(size=28),axis.text = element_text(size=20))+
  theme(plot.title = element_text(size=24,hjust=0.5))
```

## Model results indicate the lowest possible sum of squared error

```{r residual, echo=TRUE,results=TRUE}
model_aug<-broom::augment(b_gompertz)

sum((model_aug$.resid)^2) # Sum of the squared error

```

<br/>

If we compare different model runs from the trace output we can see this is the smallest sum of squared errors. No other model will get lower this number.

## Adding confidence intervals is easy

::: small-code
```{r, echo=TRUE,results=TRUE}
conf<-as_tibble(predFit(b_gompertz,
            newdata = list(animal_age=age_series),
            interval="confidence"),
            level=0.95) 
conf$age=bison_f_predicted$age_series
head(conf,n=4) %>% 
  kable() %>% 
  kable_classic()

#plot+geom_ribbon(data=conf...)
```

Model fits so well, the confidence intervals don't even show on plot.
:::

```{r confint, eval=FALSE}
ggplot() +
  geom_point(data = knz_bison_age, 
             aes(x = animal_age, y = animal_weight),
             size = 1,
             alpha = 0.2,color="darkorchid") +
  geom_line(data = bison_f_predicted, 
            aes(x = age_series, y = pred),
            color = "blue",
            size = 1) +
  geom_ribbon(data=conf,aes(x=age_series,ymin=lwr,ymax=upr),alpha=0.5,fill="blue")+
  theme_minimal()+
    xlab('Age')+
  ylab('Weight')+
  ggtitle("NLS Model Prediction of bison females")+
  theme(axis.title = element_text(size=28),axis.text = element_text(size=20))+
  theme(plot.title = element_text(size=30,hjust=0.5))
```

## Summary

-   Break linear assumption

-   Best used with an underlying model

-   Feed initial guess (How?)

::: fragment
1)  Literature/Theory
:::

::: fragment
2)  From data
:::

::: fragment
3)  Graph
:::

::: fragment
4)  Create starting grids
:::

## NLS place in the world {background-image="img/skywalk.webp"}

:::fragment
::: box
Machine Learning 
:::
:::

<br/>
<br/>

::: fragment
::: box
Non Linear Least Squares
:::
:::

<br/>
<br/>

:::fragment
::: box
Optimization
:::
:::

## NLS falls under the optimization umbrella

Many flavors and varieties of optimization

As general as possible

$$
\begin{aligned}
V(x,c)&=\max_c f(x,c) &\text{Subject to} \\
x&\ge0\\
c&\ge0 \\
x&=g(x,c)
\end{aligned}
$$

Used extensively in economic research, numerical modelling, engineering, and geophysics

## Which method to use?

Depends on the question being asked

- What mathematical form is the optimization equation in?

    - Maximum likelihood estimation is different than quadratic programming
    
- Do I need it to be fast or accurate?

How many/form of paramters?

***Best to use methods that you understand than ones you don't***

## Optimization toolkit highlights

optim/optimx: Workhorse functions in R 

quadprog: [Used by a GP I advised in 2021](https://www.fishwallet.net/) and by the [Salmon Stocks GP now](https://bren.ucsb.edu/projects/applying-portfolio-theory-improve-spatial-recovery-planning-pacific-salmon)

GA: Genetic algorithms are the best global tool that I know of

NLoptr: [New project trying to keep syntax of alogrithms the same across computer languages](https://nlopt.readthedocs.io/en/latest/NLopt_Introduction/)

[List of every optimization function with short descriptions](https://cran.r-project.org/web/views/Optimization.html)

## Static Slides in case shiny app doesn't work {#sec-model}

::: columns
::: {.column width="50%"}
How we could use step 2 and 3 in this case?

Asymptotic body mass $b1$ implies a max body length we could take the biggest observed female or generally look at the graph

Age inflection point $b3$ is where the curve starts bending

Instantaneous growth-rate $b2$ is kind of weird, but you could manipulate a Gompertz model to see how it changes the model
:::

::: {.column width="50%"}
```{r combeinplot, out.height='50%',fig.align='center'}
knz_plt+ geom_line(data=df1,aes(x=age,y=weight),color="blue",size=2)
```

[Back to slides](#sec-interactive)
:::
:::
